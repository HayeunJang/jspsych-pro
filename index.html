<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Speech Recording Experiment</title>
  <link rel="stylesheet" href="https://unpkg.com/jspsych@8.0.0/css/jspsych.css">
  <script src="https://unpkg.com/jspsych@8.0.0"></script>
  <script src="https://unpkg.com/@jspsych/plugin-html-button-response@2.0.0"></script>
  <script src="https://unpkg.com/@jspsych/plugin-survey-html-form@2.0.0"></script>
  <style>
    .recording-container {
      text-align: center;
      padding: 40px;
      max-width: 800px;
      margin: 0 auto;
    }
    .sentence-display {
      font-size: 28px;
      font-weight: bold;
      padding: 30px;
      margin: 30px 0;
      background: #f0f0f0;
      border-radius: 10px;
      line-height: 1.6;
    }
    .recording-status {
      font-size: 20px;
      margin: 20px 0;
      min-height: 30px;
    }
    .recording-active {
      color: #dc3545;
      animation: blink 1s infinite;
    }
    @keyframes blink {
      0%, 50% { opacity: 1; }
      51%, 100% { opacity: 0.3; }
    }
    .timer {
      font-size: 24px;
      font-weight: bold;
      margin: 15px 0;
    }
    .control-buttons {
      margin-top: 30px;
    }
    .control-buttons button {
      font-size: 18px;
      padding: 15px 40px;
      margin: 0 10px;
      cursor: pointer;
    }
    .record-btn {
      background-color: #dc3545;
      color: white;
      border: none;
      border-radius: 5px;
    }
    .record-btn:hover:not(:disabled) {
      background-color: #c82333;
    }
    .stop-btn {
      background-color: #28a745;
      color: white;
      border: none;
      border-radius: 5px;
    }
    .stop-btn:hover:not(:disabled) {
      background-color: #218838;
    }
    .next-btn {
      background-color: #007bff;
      color: white;
      border: none;
      border-radius: 5px;
    }
    .next-btn:hover:not(:disabled) {
      background-color: #0069d9;
    }
    button:disabled {
      opacity: 0.5;
      cursor: not-allowed;
    }
  </style>
</head>
<body>
  <div id="jspsych-target"></div>
  
  <script>
    /******************************************************
     * Speech Recording Experiment - Manual Control
     ******************************************************/

    console.log('Script starting...');

    /* ===== CONFIG ===== */
    const GAS_ENDPOINT = 'https://script.google.com/macros/s/AKfycbwosYp-_QYiNIxzXrB9kK3pVNoU9M_3djYrYUaIlX0V5MvrkdKZjVdvBLOuw_O_7NRM-g/exec';

    /* ===== UI TEXTS ===== */
    const TEXTS = {
      welcomeTitle: 'Speech Recording Experiment',
      welcomeBody: 'í™”ë©´ì— í‘œì‹œë˜ëŠ” ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì½ì–´ì£¼ì„¸ìš”.<br><strong>ì¡°ìš©í•œ í™˜ê²½ì—ì„œ ì§„í–‰í•´ì£¼ì„¸ìš”.</strong>',
      startBtn: 'Start',
      ready: 'ì¤€ë¹„ë˜ë©´ ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”',
      recording: 'ğŸ”´ ë…¹ìŒ ì¤‘...',
      stopped: 'ë…¹ìŒì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.',
      recordBtn: 'ë…¹ìŒ ì‹œì‘',
      stopBtn: 'ë…¹ìŒ ì™„ë£Œ',
      nextBtn: 'ë‹¤ìŒ',
      endTitle: 'ê°ì‚¬í•©ë‹ˆë‹¤!',
      endBody: 'ì‹¤í—˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë…¹ìŒ íŒŒì¼ì„ ì—…ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤...',
      finishBtn: 'ì¢…ë£Œ'
    };

    /* ===== SENTENCES TO RECORD ===== */
    const SENTENCES = [
      "ì•ˆë…•",
      "ì˜ê°€"
    ];

    /* ===== GLOBAL STATE ===== */
    let mediaRecorder = null;
    let audioChunks = [];
    let participantId = null;
    let currentTimerInterval = null;
    let isRecording = false;

    /* ===== INIT ===== */
    const jsPsych = initJsPsych({
      display_element: 'jspsych-target',
      on_finish: async () => {
        console.log('Experiment finished');
        // ì—…ë¡œë“œëŠ” ì´ë¯¸ ê° ë…¹ìŒ í›„ ì™„ë£Œë¨
      }
    });

    /* ===== WELCOME ===== */
    const welcome = {
      type: jsPsychHtmlButtonResponse,
      stimulus: `<h2>${TEXTS.welcomeTitle}</h2><p>${TEXTS.welcomeBody}</p>`,
      choices: [TEXTS.startBtn]
    };

    /* ===== MICROPHONE PERMISSION ===== */
    const mic_permission = {
      type: jsPsychHtmlButtonResponse,
      stimulus: '<h3>ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­</h3><p>ë…¹ìŒì„ ìœ„í•´ ë§ˆì´í¬ ì‚¬ìš©ì„ í—ˆìš©í•´ì£¼ì„¸ìš”.</p>',
      choices: ['ë§ˆì´í¬ í—ˆìš©'],
      on_finish: async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
          stream.getTracks().forEach(track => track.stop());
          console.log('Microphone permission granted');
        } catch (err) {
          alert('ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ë¥¼ í—ˆìš©í•´ì£¼ì„¸ìš”.');
          console.error('Microphone error:', err);
        }
      }
    };

    /* ===== RECORDING TRIAL FACTORY ===== */
    function makeRecordingTrial(sentence, index) {
      return {
        type: jsPsychHtmlButtonResponse,
        stimulus: () => {
          return `
            <div class="recording-container">
              <div class="sentence-display">${sentence}</div>
              <div class="recording-status" id="status">${TEXTS.ready}</div>
              <div class="timer" id="timer"></div>
              <div class="control-buttons">
                <button class="record-btn" id="recordBtn" onclick="handleRecord()">${TEXTS.recordBtn}</button>
                <button class="stop-btn" id="stopBtn" onclick="handleStop()" disabled>${TEXTS.stopBtn}</button>
                <button class="next-btn" id="nextBtn" style="display:none;">${TEXTS.nextBtn}</button>
              </div>
            </div>
          `;
        },
        choices: [],
        on_load: function() {
          console.log(`Trial ${index + 1} loaded: "${sentence}"`);
          audioChunks = [];
          isRecording = false;
          
          // ì „ì—­ í•¨ìˆ˜ë¡œ ë²„íŠ¼ í•¸ë“¤ëŸ¬ ì •ì˜
          window.handleRecord = async () => {
            const recordBtn = document.getElementById('recordBtn');
            const stopBtn = document.getElementById('stopBtn');
            const statusEl = document.getElementById('status');
            
            if (isRecording) return;
            
            try {
              await startRecording();
              isRecording = true;
              
              recordBtn.disabled = true;
              stopBtn.disabled = false;
              
              if (statusEl) {
                statusEl.innerHTML = TEXTS.recording;
                statusEl.classList.add('recording-active');
              }
              
              // íƒ€ì´ë¨¸ ì‹œì‘
              let seconds = 0;
              currentTimerInterval = setInterval(() => {
                seconds++;
                const timerEl = document.getElementById('timer');
                if (timerEl) {
                  timerEl.textContent = `${seconds}ì´ˆ`;
                }
              }, 1000);
              
              console.log('Recording started by user');
            } catch (err) {
              console.error('Failed to start recording:', err);
              alert('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ' + err.message);
            }
          };
          
          window.handleStop = async () => {
            const recordBtn = document.getElementById('recordBtn');
            const stopBtn = document.getElementById('stopBtn');
            const nextBtn = document.getElementById('nextBtn');
            const statusEl = document.getElementById('status');
            
            if (!isRecording) return;
            
            try {
              await stopRecording();
              isRecording = false;
              
              stopBtn.disabled = true;
              
              if (statusEl) {
                statusEl.innerHTML = 'WAVë¡œ ë³€í™˜ ì¤‘...';
                statusEl.classList.remove('recording-active');
              }
              
              // íƒ€ì´ë¨¸ ì •ì§€
              if (currentTimerInterval) {
                clearInterval(currentTimerInterval);
                currentTimerInterval = null;
              }
              
              // ë…¹ìŒ íŒŒì¼ì„ WAVë¡œ ë³€í™˜
              if (audioChunks.length > 0) {
                const webmBlob = new Blob(audioChunks, { type: 'audio/webm' });
                console.log('WebM blob size:', webmBlob.size, 'bytes');
                
                // WebMì„ WAVë¡œ ë³€í™˜
                const wavBlob = await convertWebMToWav(webmBlob);
                console.log('WAV blob size:', wavBlob.size, 'bytes');
                
                // ì¦‰ì‹œ ì—…ë¡œë“œ
                if (statusEl) {
                  statusEl.innerHTML = 'â³ ì—…ë¡œë“œ ì¤‘...';
                }
                
                const success = await uploadSingleRecording({
                  sentence: sentence,
                  index: index,
                  blob: wavBlob,
                  timestamp: new Date().toISOString()
                });
                
                if (success) {
                  console.log(`Recording ${index + 1} uploaded successfully`);
                  if (statusEl) {
                    statusEl.innerHTML = 'âœ… ì—…ë¡œë“œ ì™„ë£Œ! ë‹¤ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.';
                  }
                } else {
                  console.error(`Failed to upload recording ${index + 1}`);
                  if (statusEl) {
                    statusEl.innerHTML = 'âŒ ì—…ë¡œë“œ ì‹¤íŒ¨. ë‹¤ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.';
                  }
                }
              }
              
              // ë‹¤ìŒ ë²„íŠ¼ í‘œì‹œ
              if (nextBtn) {
                nextBtn.style.display = 'inline-block';
                nextBtn.onclick = () => {
                  jsPsych.finishTrial({
                    task: 'recording',
                    sentence: sentence,
                    sentence_index: index,
                    timestamp: new Date().toISOString()
                  });
                };
              }
              
              console.log('Recording stopped by user');
            } catch (err) {
              console.error('Failed to stop recording:', err);
              if (statusEl) {
                statusEl.innerHTML = 'ì˜¤ë¥˜ ë°œìƒ: ' + err.message;
              }
            }
          };
        }
      };
    }

    /* ===== RECORDING FUNCTIONS ===== */
    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        
        // WAV í¬ë§·ì„ ìœ„í•œ ì˜µì…˜ ì„¤ì •
        const options = { mimeType: 'audio/webm' }; // ë¸Œë¼ìš°ì €ëŠ” webmìœ¼ë¡œ ë…¹ìŒ
        mediaRecorder = new MediaRecorder(stream, options);
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunks.push(event.data);
          }
        };
        
        mediaRecorder.start();
        console.log('MediaRecorder started');
      } catch (err) {
        console.error('Recording error:', err);
        throw err;
      }
    }

    function stopRecording() {
      return new Promise((resolve) => {
        if (!mediaRecorder || mediaRecorder.state === 'inactive') {
          resolve();
          return;
        }
        
        mediaRecorder.onstop = () => {
          mediaRecorder.stream.getTracks().forEach(track => track.stop());
          console.log('MediaRecorder stopped');
          resolve();
        };
        
        mediaRecorder.stop();
      });
    }

    /* ===== WEBM TO WAV CONVERSION ===== */
    async function convertWebMToWav(webmBlob) {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const arrayBuffer = await webmBlob.arrayBuffer();
      const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
      
      // WAV íŒŒì¼ ìƒì„±
      const wavBlob = audioBufferToWav(audioBuffer);
      return wavBlob;
    }

    function audioBufferToWav(audioBuffer) {
      const numChannels = audioBuffer.numberOfChannels;
      const sampleRate = audioBuffer.sampleRate;
      const format = 1; // PCM
      const bitDepth = 16;
      
      const bytesPerSample = bitDepth / 8;
      const blockAlign = numChannels * bytesPerSample;
      
      const samples = audioBuffer.getChannelData(0);
      const dataLength = samples.length * blockAlign;
      
      const buffer = new ArrayBuffer(44 + dataLength);
      const view = new DataView(buffer);
      
      // WAV í—¤ë” ì‘ì„±
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + dataLength, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true); // fmt chunk size
      view.setUint16(20, format, true);
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * blockAlign, true);
      view.setUint16(32, blockAlign, true);
      view.setUint16(34, bitDepth, true);
      writeString(view, 36, 'data');
      view.setUint32(40, dataLength, true);
      
      // ì˜¤ë””ì˜¤ ë°ì´í„° ì‘ì„±
      const offset = 44;
      for (let i = 0; i < samples.length; i++) {
        const sample = Math.max(-1, Math.min(1, samples[i]));
        const int16 = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
        view.setInt16(offset + i * 2, int16, true);
      }
      
      return new Blob([buffer], { type: 'audio/wav' });
    }

    function writeString(view, offset, string) {
      for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
      }
    }

    /* ===== DEMOGRAPHICS ===== */
    const demographics = {
      type: jsPsychSurveyHtmlForm,
      preamble: '<h3>ì°¸ê°€ì ì •ë³´</h3><p>ì•„ë˜ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.</p>',
      html: `
        <div style="text-align: left; max-width: 500px; margin: 0 auto;">
          <p><label for="gender"><strong>ì„±ë³„:</strong></label><br>
          <input type="radio" name="gender" value="ë‚¨" required> ë‚¨
          <input type="radio" name="gender" value="ì—¬" required> ì—¬</p>
          
          <p><label for="birth_year"><strong>íƒœì–´ë‚œ í•´:</strong></label><br>
          <input type="text" id="birth_year" name="birth_year" placeholder="YYYY (ì˜ˆ: 1995)" pattern="[0-9]{4}" required style="width: 150px;"></p>
          
          <p><label for="birth_month"><strong>íƒœì–´ë‚œ ì›”:</strong></label><br>
          <input type="text" id="birth_month" name="birth_month" placeholder="MM (ì˜ˆ: 03)" pattern="[0-9]{2}" required style="width: 80px;"></p>
          
          <p><label for="native_lang"><strong>ëª¨êµ­ì–´:</strong></label><br>
          <input type="text" id="native_lang" name="native_lang" placeholder="ì˜ˆ: í•œêµ­ì–´" required style="width: 200px;"></p>
          
          <p><label for="dialect"><strong>ë°©ì–¸:</strong></label><br>
          <input type="text" id="dialect" name="dialect" placeholder="ì˜ˆ: ì„œìš¸, ê²½ìƒë„" style="width: 200px;"></p>
          
          <p><label for="foreign_lang"><strong>ì™¸êµ­ì–´:</strong></label><br>
          <input type="text" id="foreign_lang" name="foreign_lang" placeholder="ì˜ˆ: ì˜ì–´, ì¼ë³¸ì–´" style="width: 300px;"></p>
        </div>
      `,
      button_label: 'ì œì¶œ',
      data: { task: 'demographics' },
      on_finish: (data) => {
        data.timestamp = new Date().toISOString();
        participantId = 'P' + Date.now();
        data.participant_id = participantId;
        console.log('Participant ID:', participantId);
        console.log('Demographics:', data.response);
      }
    };

    /* ===== END ===== */
    const end = {
      type: jsPsychHtmlButtonResponse,
      stimulus: `<h2>${TEXTS.endTitle}</h2><p>ì‹¤í—˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!</p>`,
      choices: [TEXTS.finishBtn]
    };

    /* ===== BUILD TIMELINE ===== */
    const recording_trials = SENTENCES.map((sentence, index) => 
      makeRecordingTrial(sentence, index)
    );

    /* ===== RUN ===== */
    console.log('Starting experiment...');
    jsPsych.run([
      welcome,
      mic_permission,
      ...recording_trials,
      demographics,
      end
    ]);

    /* ===== GOOGLE DRIVE UPLOAD - ê°œë³„ ë…¹ìŒ ì¦‰ì‹œ ì—…ë¡œë“œ ===== */
    async function uploadSingleRecording(recordingData) {
      if (!GAS_ENDPOINT || GAS_ENDPOINT === 'YOUR_APPS_SCRIPT_URL') {
        console.error('Google Apps Script endpoint not configured!');
        alert('ì—…ë¡œë“œ ì‹¤íŒ¨: Google Apps Script URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.');
        return false;
      }

      try {
        // demographics ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ ì…ë ¥ëœ ê²½ìš°)
        const demoData = jsPsych.data.get().filter({task: 'demographics'}).values()[0];
        const demographics = demoData?.response || {};

        const base64Audio = await blobToBase64(recordingData.blob);
        
        const payload = {
          participant_id: participantId || 'unknown',
          sentence_index: recordingData.index,
          sentence: recordingData.sentence,
          audio_data: base64Audio,
          timestamp: recordingData.timestamp,
          demographics: demographics
        };

        console.log(`Uploading recording ${recordingData.index + 1}...`);
        console.log('Payload (without audio_data):', {
          ...payload,
          audio_data: `[${base64Audio.length} bytes]`
        });

        const response = await fetch(GAS_ENDPOINT, {
          method: 'POST',
          headers: { 
            'Content-Type': 'application/json'
          },
          body: JSON.stringify(payload),
          redirect: 'follow'
        });

        const responseText = await response.text();
        console.log(`Response:`, responseText);

        if (!response.ok || responseText.includes('error')) {
          throw new Error(`Upload failed: ${responseText}`);
        }

        console.log(`Successfully uploaded recording ${recordingData.index + 1}`);
        return true;
        
      } catch (err) {
        console.error('Upload error:', err);
        alert(`ë…¹ìŒ ${recordingData.index + 1} ì—…ë¡œë“œ ì‹¤íŒ¨: ${err.message}\nê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”.`);
        return false;
      }
    }

    function blobToBase64(blob) {
      return new Promise((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result.split(',')[1]);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      });
    }
  </script>
</body>
</html>
